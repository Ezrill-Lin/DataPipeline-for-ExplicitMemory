{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available: True\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from datasets import Dataset, load_from_disk\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "print(f'CUDA is available: {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 9948 pieces of data labeled.\n"
     ]
    }
   ],
   "source": [
    "# load scores\n",
    "with open('llm_scores.jsonl', 'r', encoding='utf-8') as f:\n",
    "    scores = [json.loads(line) for line in f]\n",
    "\n",
    "# load extracted texts\n",
    "with open('texts_extracted.jsonl', 'r', encoding='utf-8') as f:\n",
    "    texts = [json.loads(line) for line in f]\n",
    "\n",
    "# combine texts and scores\n",
    "scored_texts = []\n",
    "for s in scores:\n",
    "    idx = s['index']\n",
    "    score = s['score']\n",
    "    if not score:\n",
    "        continue\n",
    "    text = texts[idx]['extracted_text']\n",
    "    scored_texts.append({\n",
    "        'text': text,\n",
    "        'label': 1 if score >= float(4) else 0\n",
    "    })\n",
    "\n",
    "# get sft data for TinyBERT\n",
    "dataset = Dataset.from_list(scored_texts)\n",
    "print(f'Total of {len(dataset)} pieces of data labeled.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9948/9948 [00:46<00:00, 215.14 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize BERT training\n",
    "bert = \"huawei-noah/TinyBERT_General_4L_312D\"\n",
    "tokenizer = BertTokenizer.from_pretrained(bert)\n",
    "\n",
    "def tokenize(sample):\n",
    "    return tokenizer(\n",
    "        text=sample['text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "    )\n",
    "\n",
    "dataset = dataset.map(tokenize).shuffle(seed=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 8953\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 995\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_split = dataset.train_test_split(test_size=0.1, seed=6)\n",
    "train_dataset = dataset_split[\"train\"]\n",
    "eval_dataset = dataset_split[\"test\"]\n",
    "\n",
    "dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\linxi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# training setup\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    bert,\n",
    "    num_labels=2  \n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./tinybert-checkpoints\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    pred = logits.argmax(axis=-1)\n",
    "\n",
    "    acc = accuracy_score(labels, pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, pred, average='binary')\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2240' max='2240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2240/2240 11:04, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.568100</td>\n",
       "      <td>0.573817</td>\n",
       "      <td>0.719598</td>\n",
       "      <td>0.747487</td>\n",
       "      <td>0.884101</td>\n",
       "      <td>0.810075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.529900</td>\n",
       "      <td>0.545423</td>\n",
       "      <td>0.739698</td>\n",
       "      <td>0.770235</td>\n",
       "      <td>0.876672</td>\n",
       "      <td>0.820014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.498800</td>\n",
       "      <td>0.515048</td>\n",
       "      <td>0.746734</td>\n",
       "      <td>0.808199</td>\n",
       "      <td>0.820208</td>\n",
       "      <td>0.814159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.499600</td>\n",
       "      <td>0.523766</td>\n",
       "      <td>0.740704</td>\n",
       "      <td>0.824726</td>\n",
       "      <td>0.783061</td>\n",
       "      <td>0.803354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.463500</td>\n",
       "      <td>0.527126</td>\n",
       "      <td>0.741709</td>\n",
       "      <td>0.814199</td>\n",
       "      <td>0.800892</td>\n",
       "      <td>0.807491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.451800</td>\n",
       "      <td>0.536603</td>\n",
       "      <td>0.730653</td>\n",
       "      <td>0.838063</td>\n",
       "      <td>0.745914</td>\n",
       "      <td>0.789308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.408000</td>\n",
       "      <td>0.534458</td>\n",
       "      <td>0.746734</td>\n",
       "      <td>0.831496</td>\n",
       "      <td>0.784547</td>\n",
       "      <td>0.807339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.419200</td>\n",
       "      <td>0.533917</td>\n",
       "      <td>0.752764</td>\n",
       "      <td>0.831008</td>\n",
       "      <td>0.796434</td>\n",
       "      <td>0.813354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(\"tinybert-filter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
